{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inventory Optimization and Sustainability Analysis**\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Minimize waste by optimizing inventory levels.\n",
    "* Identify the most efficient purchasing strategies based on sales, procurement, and inventory data.\n",
    "* Evaluate product sales performance to formulate a sustainable inventory management approach.\n",
    "\n",
    "**1. Data Preprocessing:**  \n",
    "* Consolidate all CSV files into a unified master dataset.  \n",
    "* Screen for any missing or erroneous entries.  \n",
    "* Standardize date formats for consistent time series analysis.\n",
    "\n",
    "**2. Inventory Analysis:**\n",
    "* Assess inventory status at the year's start and end using BegInvFINAL12312016.csv and EndInvFINAL12312016.csv.  \n",
    "* Pinpoint products with the highest and lowest inventory presence.\n",
    "\n",
    "\n",
    "**3. Sales Analysis:**\n",
    "* Examine SalesFINAL12312016.csv to identify bestsellers and products with sluggish sales.\n",
    "* Analyze sales trends over time, considering variables such as sales quantity, sales price, and date.\n",
    "\n",
    "\n",
    "**4. Purchasing Analysis:**\n",
    "* Evaluate procurement activities using PurchasesFINAL12312016.csv and InvoicePurchases12312016.csv.\n",
    "* Investigate purchase volumes from different suppliers, procurement costs, and supply chain processes.\n",
    "\n",
    "**5. Optimal Stock Level Calculation:**\n",
    "* Determine the optimal stock level for each product by leveraging sales, procurement, and inventory data.\n",
    "* Propose stock levels tailored to the sales velocity of products and supply lead times.\n",
    "\n",
    "**Conclusion:**  \n",
    "The insights derived from these analyses will provide recommendations for managing inventory in a more efficient and sustainable manner, aiming to cut costs and prevent overstocking and waste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "purchase_prices = pd.read_csv('../data/InventoryAnalysisCaseStudy/2017PurchasePricesDec.csv')\n",
    "beg_inv = pd.read_csv('../data/InventoryAnalysisCaseStudy/BegInvFINAL12312016.csv')\n",
    "end_inv = pd.read_csv('../data/InventoryAnalysisCaseStudy/EndInvFINAL12312016.csv')\n",
    "invoice_purchases = pd.read_csv('../data/InventoryAnalysisCaseStudy/InvoicePurchases12312016.csv')\n",
    "purchases = pd.read_csv('../data/InventoryAnalysisCaseStudy/PurchasesFINAL12312016.csv')\n",
    "sales = pd.read_csv('../data/InventoryAnalysisCaseStudy/SalesFINAL12312016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase_prices Columns:\n",
      "['Brand', 'Description', 'Price', 'Size', 'Volume', 'Classification', 'PurchasePrice', 'VendorNumber', 'VendorName']\n",
      "\n",
      "beg_inv Columns:\n",
      "['InventoryId', 'Store', 'City', 'Brand', 'Description', 'Size', 'onHand', 'Price', 'startDate']\n",
      "\n",
      "end_inv Columns:\n",
      "['InventoryId', 'Store', 'City', 'Brand', 'Description', 'Size', 'onHand', 'Price', 'endDate']\n",
      "\n",
      "invoice_purchases Columns:\n",
      "['VendorNumber', 'VendorName', 'InvoiceDate', 'PONumber', 'PODate', 'PayDate', 'Quantity', 'Dollars', 'Freight', 'Approval']\n",
      "\n",
      "purchases Columns:\n",
      "['InventoryId', 'Store', 'Brand', 'Description', 'Size', 'VendorNumber', 'VendorName', 'PONumber', 'PODate', 'ReceivingDate', 'InvoiceDate', 'PayDate', 'PurchasePrice', 'Quantity', 'Dollars', 'Classification']\n",
      "\n",
      "sales Columns:\n",
      "['InventoryId', 'Store', 'Brand', 'Description', 'Size', 'SalesQuantity', 'SalesDollars', 'SalesPrice', 'SalesDate', 'Volume', 'Classification', 'ExciseTax', 'VendorNo', 'VendorName']\n"
     ]
    }
   ],
   "source": [
    "print(\"purchase_prices Columns:\")\n",
    "print(purchase_prices.columns.tolist())\n",
    "\n",
    "print(\"\\nbeg_inv Columns:\")\n",
    "print(beg_inv.columns.tolist())\n",
    "\n",
    "print(\"\\nend_inv Columns:\")\n",
    "print(end_inv.columns.tolist())\n",
    "\n",
    "print(\"\\ninvoice_purchases Columns:\")\n",
    "print(invoice_purchases.columns.tolist())\n",
    "\n",
    "print(\"\\npurchases Columns:\")\n",
    "print(purchases.columns.tolist())\n",
    "\n",
    "print(\"\\nsales Columns:\")\n",
    "print(sales.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:10:53.859455Z",
     "iopub.status.busy": "2023-11-04T10:10:53.859106Z",
     "iopub.status.idle": "2023-11-04T10:10:54.787823Z",
     "shell.execute_reply": "2023-11-04T10:10:54.786547Z",
     "shell.execute_reply.started": "2023-11-04T10:10:53.859428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for missing data in each dataset\n",
    "datasets = [purchase_prices, beg_inv, end_inv, invoice_purchases, purchases, sales]\n",
    "dataset_names = [\"purchase_prices\", \"beg_inv\", \"end_inv\", \"invoice_purchases\", \"purchases\", \"sales\"]\n",
    "\n",
    "for name, data in zip(dataset_names, datasets):\n",
    "    missing_values = data.isnull().sum()\n",
    "    non_zero_missing_values = missing_values[missing_values > 0]\n",
    "    \n",
    "    if not non_zero_missing_values.empty:\n",
    "        print(f\"\\nMissing values in {name}:\")\n",
    "        print(non_zero_missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values is a pivotal step in our data analysis journey. Different data segments might demand distinct strategies. Let's collaboratively address each dataset and decide on the most appropriate course of action:\n",
    "\n",
    "**purchase_prices:**\n",
    "* **Description, Size, and Volume:** There's a limited number of missing entries here. We have a few options: removing these specific rows, or, for a more informed approach, substituting these gaps with the most commonly observed value (mode). We'll go with removing these rows  \n",
    "\n",
    "**end_inv:**\n",
    "* City: An immediate solution could be to replace the missing 'City' entries with the most frequently occurring city (mode). However, if our 'Store' column has location insights, we might consider using it for a more informed fill. If neither works, marking them as 'Unknown' might be our best bet. We'll try our chances with using 'Store' column.   \n",
    "\n",
    "**invoice_purchases:**\n",
    "* Approval: If we interpret 'Approval' as a binary indicator (e.g., Approved/Not Approved), the absences might hint that the status of these invoices hasn't been decided. We can categorize them as 'Pending' or 'Unknown' for clarity.  \n",
    "\n",
    "**purchases:**\n",
    "* Size: Mirroring our strategy with 'purchase_prices', we can discard these few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:13.825344Z",
     "iopub.status.busy": "2023-11-04T10:11:13.824929Z",
     "iopub.status.idle": "2023-11-04T10:11:15.100681Z",
     "shell.execute_reply": "2023-11-04T10:11:15.099339Z",
     "shell.execute_reply.started": "2023-11-04T10:11:13.825282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handling missing values for purchase_prices dataset\n",
    "cols_to_check = ['Description', 'Size', 'Volume']\n",
    "for col in cols_to_check:\n",
    "    purchase_prices = purchase_prices[purchase_prices[col].notna()]\n",
    "\n",
    "# Handling missing values for end_inv dataset\n",
    "if end_inv['Store'].nunique() == end_inv['City'].nunique():\n",
    "    city_store_mapping = end_inv[['Store', 'City']].drop_duplicates().set_index('Store').to_dict()['City']\n",
    "    end_inv['City'] = end_inv['City'].fillna(end_inv['Store'].map(city_store_mapping))\n",
    "else:\n",
    "    end_inv['City'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Handling missing values for invoice_purchases dataset\n",
    "invoice_purchases['Approval'].fillna('Pending', inplace=True)\n",
    "\n",
    "# Handling missing values for purchases dataset\n",
    "purchases = purchases[purchases['Size'].notna()]\n",
    "\n",
    "datasets = [purchase_prices, beg_inv, end_inv, invoice_purchases, purchases, sales]\n",
    "dataset_names = [\"purchase_prices\", \"beg_inv\", \"end_inv\", \"invoice_purchases\", \"purchases\", \"sales\"]\n",
    "\n",
    "for name, data in zip(dataset_names, datasets):\n",
    "    missing_values = data.isnull().sum()\n",
    "    non_zero_missing_values = missing_values[missing_values > 0]\n",
    "    \n",
    "    if not non_zero_missing_values.empty:\n",
    "        print(f\"\\nMissing values in {name}:\")\n",
    "        print(non_zero_missing_values)\n",
    "    else:\n",
    "        print(f\"\\nNo missing values in {name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Inventory Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:21.66156Z",
     "iopub.status.busy": "2023-11-04T10:11:21.661189Z",
     "iopub.status.idle": "2023-11-04T10:11:21.749035Z",
     "shell.execute_reply": "2023-11-04T10:11:21.747593Z",
     "shell.execute_reply.started": "2023-11-04T10:11:21.661533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grouping by Brand and Description and summarize inventory for beginning of the year\n",
    "beg_summary = beg_inv.groupby(['Brand', 'Description'])['onHand'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Grouping by Brand and Description and summarize inventory for end of the year\n",
    "end_summary = end_inv.groupby(['Brand', 'Description'])['onHand'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Identifying top 5 products at the beginning and end of the year\n",
    "top_5_beg = beg_summary.head(5)\n",
    "top_5_end = end_summary.head(5)\n",
    "\n",
    "# Identifying bottom 5 products at the beginning and end of the year\n",
    "bottom_5_beg = beg_summary.tail(5)\n",
    "bottom_5_end = end_summary.tail(5)\n",
    "\n",
    "print(\"Top 5 products at the beginning of the year:\\n\", top_5_beg)\n",
    "print(\"\\nTop 5 products at the end of the year:\\n\", top_5_end)\n",
    "print(\"\\nBottom 5 products at the beginning of the year:\\n\", bottom_5_beg)\n",
    "print(\"\\nBottom 5 products at the end of the year:\\n\", bottom_5_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**  \n",
    "\n",
    "**Top Products:**\n",
    "* \"Ketel One Vodka\" emerged as the top product by the end of the year, even though it was in the 4th position at the beginning. This could imply an increased demand or higher restocking levels for this product during the year.\n",
    "* \"Capt Morgan Spiced Rum\", initially the highest in inventory at the start of the year, narrowly missed the top position by a single unit by the year's end.\n",
    "* \"Smirnoff 80 Proof\" seems to have undergone a brand update or rebranding, as the brand number changed from 3876 to 8111 during the year. Despite this, its popularity remained consistent.\n",
    "* \"Absolut 80 Proof\" held steady, only dropping one rank from the beginning to the end of the year.\n",
    "* A new entrant, \"Jack Daniels No 7 Black\", made its way into the top 5 by the end of the year, replacing \"Maurice's Mentholated Mint\" from the beginning of the year's list.\n",
    "\n",
    "**Bottom Products:**\n",
    "* It's alarming to see products with zero inventory both at the beginning and the end of the year. It's possible that these items either never had stock during the entire year, or they had stock that was completely sold out and never replenished.\n",
    "* There isn't a significant overlap between the products in the bottom 5 of both lists, indicating that inventory for low-stock items could be fluctuating throughout the year.\n",
    "* The presence of wines and niche products among the bottom lists suggests that these might be specialty items with selective demand or limited supply.\n",
    "\n",
    "**Inventory Management Observations:**\n",
    "* **The overall high consistency among the top products suggests steady demand and effective inventory replenishment strategies for popular items.**\n",
    "* However, **the consistent zero counts at both year start and end for certain products indicate potential issues in inventory management or procurement**. It may be worthwhile to review the demand for these products and determine if it makes business sense to continue carrying them or if there might be supply chain issues preventing their restocking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Sales Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:26.65892Z",
     "iopub.status.busy": "2023-11-04T10:11:26.658574Z",
     "iopub.status.idle": "2023-11-04T10:11:26.911837Z",
     "shell.execute_reply": "2023-11-04T10:11:26.910786Z",
     "shell.execute_reply.started": "2023-11-04T10:11:26.658893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the best-selling products\n",
    "best_selling_products = sales.groupby(['Brand', 'Description']).agg({'SalesQuantity': 'sum'}).sort_values(by='SalesQuantity', ascending=False).head(10)\n",
    "print(f\"Best selling ten products:\\n{best_selling_products}\\n\")\n",
    "\n",
    "# Finding the slow-moving products\n",
    "slow_moving_products = sales.groupby(['Brand', 'Description']).agg({'SalesQuantity': 'sum'}).sort_values(by='SalesQuantity', ascending=True).head(10)\n",
    "print(f\"Slow-moving ten products:\\n{slow_moving_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:30.228179Z",
     "iopub.status.busy": "2023-11-04T10:11:30.227696Z",
     "iopub.status.idle": "2023-11-04T10:11:31.167403Z",
     "shell.execute_reply": "2023-11-04T10:11:31.166375Z",
     "shell.execute_reply.started": "2023-11-04T10:11:30.228137Z"
    }
   },
   "outputs": [],
   "source": [
    "sales['SalesDate'] = pd.to_datetime(sales['SalesDate'])\n",
    "sales_quantity_trend = sales.groupby('SalesDate').agg({'SalesQuantity': 'sum'})\n",
    "sales_quantity_trend.plot(figsize=(12, 6), title='Sales Quantity Over Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:36.727796Z",
     "iopub.status.busy": "2023-11-04T10:11:36.727383Z",
     "iopub.status.idle": "2023-11-04T10:11:37.406858Z",
     "shell.execute_reply": "2023-11-04T10:11:37.405617Z",
     "shell.execute_reply.started": "2023-11-04T10:11:36.727767Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_price_trend = sales.groupby('SalesDate').agg({'SalesPrice': 'mean'})\n",
    "avg_price_trend.plot(figsize=(12, 6), title='Average Sales Price Over Time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **There's a cyclical nature to the sales quantities, which might hint at weekly patterns or trends.**  \n",
    "1. **A significant peak is noticed around January 25th; this could be attributed to specific events, promotions, or even seasonal demands.** However, as we transition into February, there's a noticeable decline in sales, which then appears to stabilize as the month progresses.\n",
    "1. **Spirits like \"Smirnoff 80 Proof\" emerge as the top sellers, reflecting a steady demand.** On the other hand, several products are moving slowly, indicating limited sales. As these products vary in type and brand, a strategic review might be necessary to decide on their continued stocking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Purchasing Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:42.540098Z",
     "iopub.status.busy": "2023-11-04T10:11:42.539733Z",
     "iopub.status.idle": "2023-11-04T10:11:42.553901Z",
     "shell.execute_reply": "2023-11-04T10:11:42.552698Z",
     "shell.execute_reply.started": "2023-11-04T10:11:42.540066Z"
    }
   },
   "outputs": [],
   "source": [
    "vendor_purchase_volume = invoice_purchases.groupby('VendorName').agg({'Quantity': 'sum'}).sort_values(by='Quantity', ascending=False)\n",
    "print(\"Top 10 Vendors by Purchase Volume:\\n\", vendor_purchase_volume.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:44.990995Z",
     "iopub.status.busy": "2023-11-04T10:11:44.990648Z",
     "iopub.status.idle": "2023-11-04T10:11:45.189194Z",
     "shell.execute_reply": "2023-11-04T10:11:45.187319Z",
     "shell.execute_reply.started": "2023-11-04T10:11:44.990966Z"
    }
   },
   "outputs": [],
   "source": [
    "vendor_purchase_cost = purchases.groupby('VendorName').agg({'PurchasePrice': 'sum'}).sort_values(by='PurchasePrice', ascending=False)\n",
    "print(\"Top 10 Vendors by Purchase Cost:\\n\", vendor_purchase_cost.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Vendors by Purchase Cost:**\n",
    "* DIAGEO NORTH AMERICA INC stands out as the top vendor with the highest purchase cost, amounting to 3,919,293.52 US dollars.\n",
    "* The following two vendors, 'JIM BEAM BRANDS COMPANY' and 'PERNOD RICARD USA', have notable purchase costs of 2,445,075.37 and 2,002,210.70, respectively.\n",
    "* **It's interesting to see that the top 10 vendors have a significant difference in their purchase costs, with 'DIAGEO NORTH AMERICA INC' nearly leading by a margin of 1.5 million usd from the vendor in the second position.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:48.748146Z",
     "iopub.status.busy": "2023-11-04T10:11:48.747803Z",
     "iopub.status.idle": "2023-11-04T10:11:49.300447Z",
     "shell.execute_reply": "2023-11-04T10:11:49.299582Z",
     "shell.execute_reply.started": "2023-11-04T10:11:48.748118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting PODate and ReceivingDate columns to datetime\n",
    "purchases['PODate'] = pd.to_datetime(purchases['PODate'], errors='coerce')\n",
    "purchases['ReceivingDate'] = pd.to_datetime(purchases['ReceivingDate'], errors='coerce')\n",
    "\n",
    "# Checking if there are any null values after conversion\n",
    "if purchases['PODate'].isnull().any() or purchases['ReceivingDate'].isnull().any():\n",
    "    print(\"There are invalid date entries in the dataset. Please review the data.\")\n",
    "else:\n",
    "    purchases['SupplyDuration'] = (purchases['ReceivingDate'] - purchases['PODate']).dt.days\n",
    "    average_supply_duration = purchases['SupplyDuration'].mean()\n",
    "    print(\"Average Supply Duration (in days):\", average_supply_duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:51.826698Z",
     "iopub.status.busy": "2023-11-04T10:11:51.826319Z",
     "iopub.status.idle": "2023-11-04T10:11:52.386424Z",
     "shell.execute_reply": "2023-11-04T10:11:52.385358Z",
     "shell.execute_reply.started": "2023-11-04T10:11:51.826667Z"
    }
   },
   "outputs": [],
   "source": [
    "purchases['InvoiceDate'] = pd.to_datetime(purchases['InvoiceDate'])\n",
    "purchases['PayDate'] = pd.to_datetime(purchases['PayDate'])\n",
    "purchases['PaymentDuration'] = (purchases['PayDate'] - purchases['InvoiceDate']).dt.days\n",
    "\n",
    "average_payment_duration = purchases['PaymentDuration'].mean()\n",
    "print(\"Average Payment Duration (in days):\", average_payment_duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Supply and Payment Durations:**. \n",
    "* On average, it takes approximately 7.62 days for the supply process, which indicates a relatively quick turnaround for receiving products after placing an order.\n",
    "* **However, the payment duration averages around 35.66 days. This could mean that there might be longer credit terms agreed upon with the vendors or there might be some delay in the payment process.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:11:55.606744Z",
     "iopub.status.busy": "2023-11-04T10:11:55.606404Z",
     "iopub.status.idle": "2023-11-04T10:11:55.835778Z",
     "shell.execute_reply": "2023-11-04T10:11:55.834476Z",
     "shell.execute_reply.started": "2023-11-04T10:11:55.606718Z"
    }
   },
   "outputs": [],
   "source": [
    "reduced_purchases = purchases[['VendorName', 'PurchasePrice']]\n",
    "top_vendors = reduced_purchases.groupby('VendorName').sum()['PurchasePrice'].nlargest(10)\n",
    "print(top_vendors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:12:04.792061Z",
     "iopub.status.busy": "2023-11-04T10:12:04.791745Z",
     "iopub.status.idle": "2023-11-04T10:12:05.381315Z",
     "shell.execute_reply": "2023-11-04T10:12:05.380566Z",
     "shell.execute_reply.started": "2023-11-04T10:12:04.792035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bar graph for top vendors by purchase cost\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_vendors.plot(kind='bar', color='coral')\n",
    "plt.title('Top 10 Vendors by Purchase Cost')\n",
    "plt.ylabel('Purchase Cost')\n",
    "plt.xlabel('Vendor Name')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for distribution of purchase costs among the top vendors\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_vendors.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Purchase Costs Among Top Vendors')\n",
    "plt.ylabel('')  # to remove the default 'PurchasePrice' label from the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart illustrates the top 10 vendors by purchase cost. **We observe that \"DIAGEO NORTH AMERICA INC\" clearly dominates, with a significantly higher purchase cost compared to others.** The other vendors, like \"JIM BEAM BRANDS COMPANY\" and \"PERNOD RICARD USA\", have a more consistent distribution, showing a balanced spending across them.\n",
    "\n",
    "Transitioning to the pie chart, which provides a distribution of purchase costs among top vendors, we get a more granular view. \"DIAGEO NORTH AMERICA INC\" accounts for 22.4% of the total purchase costs among the top vendors. The other vendors hold percentages ranging from 5.6% to 14%, indicating a more even distribution of costs among them.\n",
    "\n",
    "In conclusion, while there's a dominant vendor in terms of purchase cost, the overall distribution among the top vendors is relatively even, with only a few outliers. This suggests a diversified vendor strategy, but with a few preferred partnerships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:12:13.488021Z",
     "iopub.status.busy": "2023-11-04T10:12:13.487698Z",
     "iopub.status.idle": "2023-11-04T10:12:32.108421Z",
     "shell.execute_reply": "2023-11-04T10:12:32.107181Z",
     "shell.execute_reply.started": "2023-11-04T10:12:13.487997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Style settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Histogram for Supply Duration\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(purchases['SupplyDuration'], kde=True, bins=30, color='coral')\n",
    "plt.title('Distribution of Supply Duration')\n",
    "plt.xlabel('Supply Duration (in days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram for Payment Duration\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(purchases['PaymentDuration'], kde=True, bins=30, color='teal')\n",
    "plt.title('Distribution of Payment Duration')\n",
    "plt.xlabel('Payment Duration (in days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some observations,\n",
    "* The regular intervals observed in the supply duration chart suggest that there might be specific supply cycles or replenishment schedules that are adhered to.\n",
    "* **Peaks in the supply distribution, particularly around 4, 6, 8, 10, and 12 days, might indicate standard supply contract durations or preferred restocking periods.**\n",
    "* **The oscillation in payment durations, especially between 25 to 45 days, suggests variability in the terms of payment or potential inconsistencies in payment execution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:11.888038Z",
     "iopub.status.busy": "2023-11-04T10:13:11.887613Z",
     "iopub.status.idle": "2023-11-04T10:13:12.613925Z",
     "shell.execute_reply": "2023-11-04T10:13:12.612803Z",
     "shell.execute_reply.started": "2023-11-04T10:13:11.887979Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date = sales['SalesDate'].min()\n",
    "end_date = sales['SalesDate'].max()\n",
    "total_days = (end_date - start_date).days\n",
    "\n",
    "# Calculating Sales Velocity for each product\n",
    "sales_velocity = sales.groupby(['Brand', 'Description']).agg(Total_Sales=('SalesQuantity', 'sum')).reset_index()\n",
    "sales_velocity['Sales_Per_Day'] = sales_velocity['Total_Sales'] / total_days\n",
    "\n",
    "purchases.loc[:, 'Lead_Time'] = (purchases['ReceivingDate'] - purchases['PODate']).dt.days\n",
    "lead_times = purchases.groupby(['Brand', 'Description']).agg(Avg_Lead_Time=('Lead_Time', 'mean')).reset_index()\n",
    "\n",
    "# Merging the data\n",
    "merged_data = pd.merge(sales_velocity, lead_times, on=['Brand', 'Description'], how='left')\n",
    "\n",
    "# Calculating Optimal Stock Level\n",
    "merged_data['Optimal_Stock_Level'] = merged_data['Sales_Per_Day'] * merged_data['Avg_Lead_Time']\n",
    "\n",
    "# Calculating Safety Stock using maximum sales for each product\n",
    "max_sales = sales.groupby(['Brand', 'Description']).agg(Max_Daily_Sales=('SalesQuantity', 'max')).reset_index()\n",
    "merged_data = pd.merge(merged_data, max_sales, on=['Brand', 'Description'], how='left')\n",
    "\n",
    "merged_data['Safety_Stock'] = merged_data['Max_Daily_Sales'] - merged_data['Sales_Per_Day']\n",
    "merged_data['Recommended_Stock_Level'] = merged_data['Optimal_Stock_Level'] + merged_data['Safety_Stock']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:17.200574Z",
     "iopub.status.busy": "2023-11-04T10:13:17.200178Z",
     "iopub.status.idle": "2023-11-04T10:13:17.21479Z",
     "shell.execute_reply": "2023-11-04T10:13:17.213852Z",
     "shell.execute_reply.started": "2023-11-04T10:13:17.200543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtering products where Sales_Per_Day value is greater than Max_Daily_Sales value\n",
    "problematic_products = merged_data[merged_data['Sales_Per_Day'] > merged_data['Max_Daily_Sales']]\n",
    "\n",
    "# Getting the number of problematic products\n",
    "num_problematic_products = len(problematic_products)\n",
    "\n",
    "# Printing problematic products to the screen\n",
    "print(f\"There are {num_problematic_products} products where the Sales_Per_Day value is greater than the Max_Daily_Sales value.\")\n",
    "if num_problematic_products > 0:\n",
    "    print(problematic_products[['Brand', 'Description', 'Sales_Per_Day', 'Max_Daily_Sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:27.087085Z",
     "iopub.status.busy": "2023-11-04T10:13:27.086702Z",
     "iopub.status.idle": "2023-11-04T10:13:27.097571Z",
     "shell.execute_reply": "2023-11-04T10:13:27.096528Z",
     "shell.execute_reply.started": "2023-11-04T10:13:27.087055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updating Max_Daily_Sales for problematic products\n",
    "merged_data.loc[merged_data['Sales_Per_Day'] > merged_data['Max_Daily_Sales'], 'Max_Daily_Sales'] = merged_data['Sales_Per_Day']\n",
    "\n",
    "# Updating Safety Stock and Recommended Stock Level after modifying Max_Daily_Sales\n",
    "merged_data['Safety_Stock'] = merged_data['Max_Daily_Sales'] - merged_data['Sales_Per_Day']\n",
    "merged_data['Recommended_Stock_Level'] = merged_data['Optimal_Stock_Level'] + merged_data['Safety_Stock']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an inventory management context, the Sales_Per_Day represents the average number of units sold per day, whereas the Max_Daily_Sales represents the highest number of units sold in a single day for a given product. Logically, the Max_Daily_Sales should never be lower than the Sales_Per_Day, as this would imply that the average daily sales are higher than the highest sales ever recorded for a single day, which is contradictory.\n",
    "\n",
    "The occurrence of such a situation could be due to various reasons, including data entry errors, outliers, or computational errors. In our dataset, we observed that there were 555 products with this inconsistency.\n",
    "\n",
    "To rectify this, we updated the Max_Daily_Sales value to be equal to the Sales_Per_Day value for these problematic products. This ensures that the Max_Daily_Sales is at least as large as the average daily sales, thereby maintaining logical consistency in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:38.367225Z",
     "iopub.status.busy": "2023-11-04T10:13:38.36599Z",
     "iopub.status.idle": "2023-11-04T10:13:38.916087Z",
     "shell.execute_reply": "2023-11-04T10:13:38.914392Z",
     "shell.execute_reply.started": "2023-11-04T10:13:38.367186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sorting the data by Recommended_Stock_Level for better visualization\n",
    "sorted_data = merged_data.sort_values(by='Recommended_Stock_Level', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(x='Recommended_Stock_Level', y='Description', data=sorted_data.head(20), palette='viridis')  # showing top 20 products for better visualization\n",
    "plt.xlabel('Recommended Stock Level')\n",
    "plt.ylabel('Product Description')\n",
    "plt.title('Recommended Stock Levels for Top 20 Products')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart visually represents the recommended stock levels for the top 20 products. \"Smirnoff 80 Proof\" stands out as the product with the highest suggested stock level, indicating it has a high sales velocity and/or longer lead times. Conversely, products at the bottom of the chart like \"Sambuca Romana Liqueur\" have comparatively lower recommended stock levels. This visualization helps in quick decision-making regarding inventory replenishment and allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:43.424986Z",
     "iopub.status.busy": "2023-11-04T10:13:43.424606Z",
     "iopub.status.idle": "2023-11-04T10:13:43.851338Z",
     "shell.execute_reply": "2023-11-04T10:13:43.84953Z",
     "shell.execute_reply.started": "2023-11-04T10:13:43.424955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the histogram for Safety Stock distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(merged_data['Safety_Stock'], bins=30, color='lightblue', edgecolor='black')\n",
    "plt.title('Distribution of Safety Stock')\n",
    "plt.xlabel('Safety Stock Quantity')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram illustrates the distribution of safety stock quantities across products. Most noticeably, a significant majority of products have their safety stock quantities clustered around zero. This means that for many products, there is either no safety stock or a very minimal amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:49.359083Z",
     "iopub.status.busy": "2023-11-04T10:13:49.358721Z",
     "iopub.status.idle": "2023-11-04T10:13:49.849172Z",
     "shell.execute_reply": "2023-11-04T10:13:49.847712Z",
     "shell.execute_reply.started": "2023-11-04T10:13:49.359054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Styling\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Creating the histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=lead_times, x='Avg_Lead_Time', bins=50, color='skyblue', kde=True)\n",
    "plt.title('Distribution of Average Lead Time')\n",
    "plt.xlabel('Average Lead Time (Days)')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram illustrates the distribution of average lead times for products. The peak around 8 days suggests that most products have an average lead time of approximately 8 days. There are also some products with shorter or longer lead times, as seen in the spread between 4 to 14 days. The smooth line (Kernel Density Estimation) provides a clearer view of the distribution's shape, confirming the concentration around the 8-day mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:53.260503Z",
     "iopub.status.busy": "2023-11-04T10:13:53.260095Z",
     "iopub.status.idle": "2023-11-04T10:13:53.724064Z",
     "shell.execute_reply": "2023-11-04T10:13:53.723223Z",
     "shell.execute_reply.started": "2023-11-04T10:13:53.26047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sorting the data by Sales_Per_Day in descending order to get top products\n",
    "top_products = sales_velocity.sort_values(by='Sales_Per_Day', ascending=False).head(20)  # you can adjust the number as needed\n",
    "\n",
    "# Creating the bar plot\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x='Description', y='Sales_Per_Day', data=top_products, palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Daily Sales Velocity by Product')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Sales Per Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar chart showcases the daily sales velocity of various products. At a glance, it's evident that \"Smirnoff 80 Proof\" has the highest sales per day, significantly outpacing other products. As we move to the right of the chart, the sales per day for each product decreases, indicating a descending order of popularity or demand. The varying shades of color from dark to light also emphasize this declining trend in sales velocity. It provides valuable insights for inventory management, helping businesses prioritize which products to stock more frequently based on their sales rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Optimal Stock Level Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:13:56.802505Z",
     "iopub.status.busy": "2023-11-04T10:13:56.802133Z",
     "iopub.status.idle": "2023-11-04T10:13:57.203206Z",
     "shell.execute_reply": "2023-11-04T10:13:57.202366Z",
     "shell.execute_reply.started": "2023-11-04T10:13:56.802478Z"
    }
   },
   "outputs": [],
   "source": [
    "end_inv['endDate'] = pd.to_datetime(end_inv['endDate'])\n",
    "latest_inventory_date = end_inv['endDate'].max()\n",
    "current_inventory = end_inv[end_inv['endDate'] == latest_inventory_date]\n",
    "\n",
    "# Summarizing the current stock levels by product.\n",
    "current_stock_levels = current_inventory.groupby(['Brand', 'Description']).agg(Current_Stock=('onHand', 'sum')).reset_index()\n",
    "\n",
    "# Merging the current stock levels with the previously calculated data.\n",
    "final_data = pd.merge(merged_data, current_stock_levels, on=['Brand', 'Description'], how='left')\n",
    "\n",
    "# Assume zero current stock for any products not present in the current inventory.\n",
    "final_data['Current_Stock'] = final_data['Current_Stock'].fillna(0)\n",
    "\n",
    "# Calculating how much of each product needs to be ordered if current stock is below recommended levels.\n",
    "final_data['Order_Quantity'] = final_data['Recommended_Stock_Level'] - final_data['Current_Stock']\n",
    "final_data['Order_Quantity'] = final_data['Order_Quantity'].clip(lower=0)  # Setting negative order quantities to zero.\n",
    "\n",
    "# Reporting the results.\n",
    "print(final_data[['Brand', 'Description', 'Current_Stock', 'Recommended_Stock_Level', 'Order_Quantity']])\n",
    "\n",
    "\n",
    "# Creating a graph using Seaborn.\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Order_Quantity', y='Description', data=final_data.sort_values('Order_Quantity', ascending=False).head(10))\n",
    "plt.title('Top 10 Products to Reorder')\n",
    "plt.xlabel('Quantity to Order')\n",
    "plt.ylabel('Product Description')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar graph displays the top 10 products that need to be reordered based on inventory data. The products are sorted by the quantity that needs to be ordered, **which is determined by the difference between the recommended stock levels and the current stock on hand.** If the current stock is below the recommended level, the product appears on the list with the quantity to order represented on the x-axis.\n",
    "\n",
    "From the graph, we can observe the following:\n",
    "\n",
    "* The product \"Josh Cellars Cab Svgn Sonoma\" has the highest quantity to reorder, approaching the 800-unit mark.\n",
    "* \"Bacardi Superior Rum Trav\" and \"Jim Beam Traveler\" follow next with slightly less quantity to order, both near or above the 600-unit mark.\n",
    "* Other products like \"Baileys Espresso Creme\" and \"Sebastiani Znfdl Sonoma Cnty\" are in the middle range with quantities to order around 400 units.\n",
    "* The product with the least quantity to reorder among the top 10 is \"Serpent's Bite Cider Whiskey,\" which is just below the 200-unit mark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:34:28.222255Z",
     "iopub.status.busy": "2023-11-04T10:34:28.221889Z",
     "iopub.status.idle": "2023-11-04T10:34:28.70699Z",
     "shell.execute_reply": "2023-11-04T10:34:28.705957Z",
     "shell.execute_reply.started": "2023-11-04T10:34:28.222227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sorting the products by recommended stock level\n",
    "sorted_data = final_data.sort_values(by='Recommended_Stock_Level', ascending=False).head(10)  # To show the top 10 products\n",
    "\n",
    "# Creating a double-column bar chart\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(sorted_data))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "bar1 = plt.bar(index, sorted_data['Current_Stock'], bar_width, label='Current Stock', color='b')\n",
    "bar2 = plt.bar([i + bar_width for i in index], sorted_data['Recommended_Stock_Level'], bar_width, label='Recommended Stock', color='r')\n",
    "\n",
    "# Setting the labels and title\n",
    "plt.xlabel('Product Description')\n",
    "plt.ylabel('Stock Quantity')\n",
    "plt.title('Top 10 Products(by Recommended Stock Levels): Current vs Recommended Stock Levels')\n",
    "plt.xticks([i + bar_width / 2 for i in index], sorted_data['Description'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the chart\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This inventory review highlights a significant surplus in the current stock levels when compared with the recommended stock levels for the top 10 products, sorted by the recommended quantity.** Notably, \"Ketel One Vodka\" and \"Rumpleminze\" showcase a pronounced excess beyond the suggested inventory, suggesting inefficiencies in stock management. The presence of stock quantities exceeding recommended levels across all observed items may lead to higher carrying costs and risk of stock becoming outdated. Immediate measures such as revising purchase orders and aligning with sales projections are advised to mitigate the risks associated with overstocking and to optimize the stock turnover ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T10:19:31.275509Z",
     "iopub.status.busy": "2023-11-04T10:19:31.2751Z",
     "iopub.status.idle": "2023-11-04T10:19:31.911497Z",
     "shell.execute_reply": "2023-11-04T10:19:31.910537Z",
     "shell.execute_reply.started": "2023-11-04T10:19:31.275478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtering the data to show the top 10 products where the ordering quantity is highest\n",
    "top_products_to_order = final_data.nlargest(10, 'Order_Quantity')\n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Indexing for the bars\n",
    "ind = np.arange(len(top_products_to_order))\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.4\n",
    "\n",
    "# Plotting current stock and recommended stock side by side\n",
    "ax.barh(ind, top_products_to_order['Current_Stock'], bar_width, color='skyblue', label='Current Stock')\n",
    "ax.barh([i + bar_width for i in ind], top_products_to_order['Recommended_Stock_Level'], bar_width, color='orange', label='Recommended Stock')\n",
    "\n",
    "# Setting the y-axis labels to product descriptions\n",
    "ax.set(yticks=[i + bar_width for i in ind], yticklabels=top_products_to_order['Description'], ylim=[2 * bar_width - 1, len(ind)])\n",
    "\n",
    "# Adding the legend\n",
    "ax.legend()\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Quantity')\n",
    "ax.set_title('Top 10 Products(by Order Quantity): Current vs Recommended Stock Levels')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph titled \"Top 10 Products (by Order Quantity): Current vs Recommended Stock Levels\" shows that for all top-selling 10 products, the current stock (blue) is below the recommended stock levels (orange), indicating a need for restocking to meet the suggested inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Products & Trends:**  \n",
    "* **\"Ketel One Vodka\" soared from 4th to the top, hinting at surging demand.**\n",
    "* \"Capt Morgan Spiced Rum\" finished a close second, just one unit behind.\n",
    "* \"Smirnoff 80 Proof\" held its ground despite a rebranding, shifting from number 3876 to 8111.\n",
    "* \"Absolut 80 Proof\" slightly dropped in rank, remaining strong.\n",
    "* Newcomer \"Jack Daniels No 7 Black\" broke into the top 5.  \n",
    "\n",
    "**Inventory Challenges:**\n",
    "* **Zero inventory items at year's start and end suggest stocking or demand issues.**\n",
    "* Low-stock items show unpredictable inventory levels.\n",
    "* **Specialty items, like select wines, linger at the bottom, indicating niche demand.**\n",
    "\n",
    "**Inventory Management Insights:**\n",
    "* **Strong consistency in top products reflects solid demand forecasting and replenishment.**\n",
    "* **Recurring zero stock levels could point to deeper inventory procurement flaws.**\n",
    "* **Sales peaked notably on January 25th, then stabilized in February.**\n",
    "* **DIAGEO NORTH AMERICA INC dominated vendor purchases** with $3.9 million, significantly ahead of others.\n",
    "* **Average supply duration is 7.62 days, but average payment stretches to 35.66 days.**\n",
    "\n",
    "\n",
    "**Operational Data Points:**  \n",
    "* Data corrections were made for 555 products to align Max_Daily_Sales with Sales_Per_Day.\n",
    "* **\"Smirnoff 80 Proof\" leads the recommended stock levels.**\n",
    "* Majority of products have minimal safety stock, implying tight inventory control.\n",
    "* **Lead times peak around 8 days.**\n",
    "* Daily sales velocity shows \"Smirnoff 80 Proof\" far ahead, emphasizing its high demand.\n",
    "\n",
    "**Stocking Strategies:**\n",
    "* \"Josh Cellars Cab Svgn Sonoma\" requires the most restocking, nearly 800 units.\n",
    "* **For the top ten products with the highest recommended stock levels, still current stock levels exceed recommended levels, hinting at overstocking and a need for inventory adjustment.**\n",
    "*  **There is a clear necessity to replenish the inventory for the most ordered 10 products to meet the recommended stock levels and ensure adequate supply to match demand.**\n",
    "* In essence, top-selling spirits demonstrate strong market demand with effective inventory turns, while zero-stock items and niche products present opportunities for inventory optimization. A significant sales event occurs in late January, and the payment terms to vendors may require review. Inventory discrepancies are being addressed, and a focus on high-velocity products like \"Smirnoff 80 Proof\" is evident. The strategy includes refining restocking practices to avoid excess inventory and associated costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3512210,
     "sourceId": 6126523,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}